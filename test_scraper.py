import json
import os
from scraper import YahooFinanceScraper

def load_stocks_from_file(filename='stocks.txt'):
    """Load stock tickers from the specified file"""
    try:
        with open(filename, 'r') as f:
            return [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        print(f"Error: {filename} not found")
        return []
    except Exception as e:
        print(f"Error reading {filename}: {e}")
        return []

def build_yahoo_finance_url(ticker):
    """Build Yahoo Finance analysis URL for a given ticker"""
    base_url = "https://finance.yahoo.com/quote/{}/analysis/"
    return base_url.format(ticker)

def test_scraper_with_all_tickers():
    """Test the scraper with all tickers from stocks.txt"""
    print("ğŸš€ Starting Yahoo Finance Scraper Test")
    print("=" * 60)
    
    # Load all tickers from stocks.txt
    tickers = load_stocks_from_file()
    if not tickers:
        print("âŒ No tickers loaded. Exiting.")
        return
    
    print(f"ğŸ“Š Loaded {len(tickers)} tickers: {', '.join(tickers)}")
    print()
    
    # Initialize the scraper
    try:
        scraper = YahooFinanceScraper()
        print("âœ… Scraper initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize scraper: {e}")
        return
    
    print()
    
    # Process each ticker
    for i, ticker in enumerate(tickers, 1):
        print(f"ğŸ”„ Processing ticker {i}/{len(tickers)}: {ticker}")
        print("-" * 40)
        
        try:
            # Build the URL for this ticker
            url = build_yahoo_finance_url(ticker)
            print(f"ğŸŒ URL: {url}")
            
            # Scrape the website
            print("ğŸ“¥ Scraping website...")
            html_content = scraper.scrape_website(ticker)
            
            if html_content:
                print("âœ… Website scraped successfully")
                
                # Parse the content
                print("ï¿½ï¿½ Parsing content...")
                ticker_data = scraper.parse_yahoo_finance_content(html_content, ticker)
                
                if ticker_data:
                    print("âœ… Content parsed successfully")
                    
                    # Output the JSON data
                    print("ï¿½ï¿½ Extracted Data:")
                    print(json.dumps(ticker_data, indent=2))
                    
                    # Summary of what was extracted
                    data_keys = list(ticker_data.get('data', {}).keys())
                    print(f"\nï¿½ï¿½ Data Summary: {len(data_keys)} data categories extracted")
                    if data_keys:
                        print(f"   Categories: {', '.join(data_keys)}")
                    
                else:
                    print("âŒ Failed to parse content")
                    print("   Raw HTML length:", len(html_content))
                    
            else:
                print("âŒ Failed to scrape website")
                
        except Exception as e:
            print(f"âŒ Error processing {ticker}: {e}")
        
        print()
        
        # Add a small delay between requests to be respectful
        if i < len(tickers):
            print("â³ Waiting 2 seconds before next request...")
            import time
            time.sleep(2)
            print()
    
    print("=" * 60)
    print("ğŸ‰ Scraper test completed!")
    print(f"ğŸ“ˆ Processed {len(tickers)} tickers")

def test_scraper_with_single_ticker(ticker='AAPL'):
    """Test the scraper with a single ticker (for debugging)"""
    print(f"ğŸ§ª Testing scraper with single ticker: {ticker}")
    print("=" * 40)
    
    try:
        scraper = YahooFinanceScraper()
        url = build_yahoo_finance_url(ticker)
        
        print(f"ğŸŒ URL: {url}")
        print("ğŸ“¥ Scraping...")
        
        html_content = scraper.scrape_website(ticker)
        if html_content:
            print("âœ… Scraped successfully")
            ticker_data = scraper.parse_yahoo_finance_content(html_content, ticker)
            if ticker_data:
                print("âœ… Parsed successfully")
                print("\nğŸ“‹ Data:")
                print(json.dumps(ticker_data, indent=2))
            else:
                print("âŒ Parse failed")
        else:
            print("âŒ Scrape failed")
            
    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    # Check if we want to test a single ticker or all tickers
    import sys
    
    if len(sys.argv) > 1:
        # Test with specific ticker
        ticker = sys.argv[1].upper()
        test_scraper_with_single_ticker(ticker)
    else:
        # Test with all tickers from stocks.txt
        test_scraper_with_all_tickers()