# ğŸš€ Yahoo Finance Manager

A comprehensive stock data management application with automated scraping, FastAPI backend, and React frontend.

## ğŸ“ **New Professional Project Structure**

```
yahoof/
â”œâ”€â”€ frontend/                    # ğŸ¨ React Frontend (Phase 2 Complete)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ common/         # Shared components
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/         # Layout components
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/          # Page components
â”‚   â”‚   â”‚   â””â”€â”€ ui/             # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ constants/          # App-wide constants
â”‚   â”‚   â”œâ”€â”€ hooks/              # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ services/           # API services
â”‚   â”‚   â”œâ”€â”€ types/              # TypeScript definitions
â”‚   â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚   â”‚   â””â”€â”€ assets/             # Static assets
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                     # âš™ï¸ FastAPI Backend (Phase 1 Complete)
â”‚   â”œâ”€â”€ api/                    # API endpoints
â”‚   â”‚   â””â”€â”€ main_api.py        # Main FastAPI application
â”‚   â”œâ”€â”€ core/                   # Core functionality
â”‚   â”‚   â”œâ”€â”€ database.py        # Database configuration
â”‚   â”‚   â””â”€â”€ db_manager_sqlalchemy.py  # Database manager
â”‚   â”œâ”€â”€ models/                 # Database models
â”‚   â”‚   â””â”€â”€ models_simple.py   # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ scripts/                # Scraping scripts
â”‚   â”‚   â”œâ”€â”€ yfinance_api_scraper.py      # Yahoo Finance scraper
â”‚   â”‚   â””â”€â”€ parallel_scrape_sqlalchemy.py # Parallel scraping
â”‚   â”œâ”€â”€ config/                 # Configuration
â”‚   â”‚   â””â”€â”€ settings.py        # Centralized settings
â”‚   â”œâ”€â”€ utils/                  # Utility functions
â”‚   â”‚   â””â”€â”€ helpers.py         # Helper utilities
â”‚   â”œâ”€â”€ tests/                  # Test files
â”‚   â”œâ”€â”€ main.py                 # Main entry point
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ venv/                       # Python virtual environment
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ requirements.txt            # Root requirements
â””â”€â”€ README.md                   # This file
```

## ğŸ¯ **Implementation Status**

### âœ… **Phase 0: SQLAlchemy Migration (COMPLETE)**
- Migrated from old `DatabaseManager` to SQLAlchemy ORM
- Updated all database operations to use SQLAlchemy
- Fixed ScrapingBee integration issues
- Comprehensive testing completed

### âœ… **Phase 1: FastAPI Backend (COMPLETE)**
- Complete REST API with all endpoints
- SQLAlchemy integration
- CORS configuration for frontend
- Comprehensive error handling
- API documentation with Swagger UI

### âœ… **Phase 2: React Frontend (COMPLETE)**
- Modern React 18 with TypeScript
- Tailwind CSS for styling
- Responsive design with mobile support
- Complete component library
- API integration with FastAPI backend

### ğŸ”„ **Phase 3: Railway Deployment (NEXT)**
- Deploy backend to Railway
- Configure production database
- Set up environment variables
- Deploy frontend to Railway

### ğŸ“‹ **Phase 4: Scraper Automation (PLANNED)**
- Railway cron jobs
- Automated scraper execution
- Database-driven scraper configuration
- Monitoring and alerting

## ğŸš€ **Quick Start**

### **Backend Setup**
```bash
# Navigate to backend directory
cd backend

# Install dependencies
pip install -r ../requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your database credentials

# Run the FastAPI server
python main.py
# or
uvicorn api.main_api:app --host 0.0.0.0 --port 8000 --reload
```

### **Frontend Setup**
```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

### **Database Setup**
```bash
# Create database tables
cd backend
python -c "from core.database import create_tables; create_tables()"
```

## ğŸ”§ **Key Features**

### **Backend (FastAPI)**
- **RESTful API**: Complete CRUD operations for stocks, tickers, and scrapers
- **SQLAlchemy ORM**: Modern database operations with connection pooling
- **Scraping Engine**: Yahoo Finance integration with ScrapingBee proxy support
- **Parallel Processing**: Multi-worker scraping with configurable batch sizes
- **Configuration Management**: Centralized settings with environment variable support

### **Frontend (React)**
- **Dashboard**: Overview statistics and recent activity
- **Stock Management**: Browse, filter, and paginate stock data
- **Scraper Management**: Create, configure, and monitor scrapers
- **Responsive Design**: Mobile-first approach with Tailwind CSS
- **Type Safety**: Full TypeScript implementation

### **Scraping System**
- **Yahoo Finance Integration**: Real-time stock data collection
- **Proxy Support**: ScrapingBee integration for rate limit avoidance
- **Batch Processing**: Efficient parallel scraping with configurable workers
- **Data Persistence**: Automatic database storage and updates

## ğŸŒ **API Endpoints**

### **Health & Status**
- `GET /health` - API health check

### **Stocks**
- `GET /api/stocks` - Get paginated stock data with filtering
- `GET /api/stocks/{ticker}` - Get specific stock details
- `GET /api/stocks/{ticker}/history` - Get stock price history

### **Tickers**
- `GET /api/tickers` - Get paginated ticker information

### **Scrapers**
- `GET /api/scrapers` - List all scrapers
- `POST /api/scrapers` - Create new scraper
- `PUT /api/scrapers/{id}` - Update scraper
- `DELETE /api/scrapers/{id}` - Delete scraper
- `POST /api/scrapers/{id}/run` - Execute scraper

### **Statistics**
- `GET /api/stats/overview` - Dashboard overview statistics

## ğŸ—„ï¸ **Database Schema**

### **Tables**
- **`scraped_data`**: Stock price and company information
- **`tickers`**: Ticker metadata and company details
- **`scrapers`**: Scraper configuration and scheduling
- **`scraper_runs`**: Execution history and results

## ğŸ” **Environment Variables**

### **Required**
```bash
DATABASE_URL=postgresql://user:password@host:port/database
```

### **Optional**
```bash
SCRAPINGBEE_API_KEY=your_api_key_here
API_DEBUG=False
LOG_LEVEL=INFO
```

## ğŸ§ª **Testing**

### **Backend Testing**
```bash
cd backend
python -m pytest tests/
```

### **Frontend Testing**
```bash
cd frontend
npm test
```

## ğŸ“Š **Performance**

### **Scraping Performance**
- **Parallel Workers**: Configurable (default: 4)
- **Batch Size**: Configurable (default: 10)
- **Rate Limiting**: Built-in delays and ScrapingBee proxy support
- **Database Optimization**: Connection pooling and efficient queries

### **API Performance**
- **Response Time**: < 100ms for most endpoints
- **Pagination**: Efficient database queries with LIMIT/OFFSET
- **Caching**: Ready for Redis integration
- **Async Support**: Full async/await implementation

## ğŸš€ **Deployment**

### **Railway (Recommended)**
- **Backend**: Python FastAPI with PostgreSQL
- **Frontend**: React static build
- **Database**: Managed PostgreSQL
- **Cron Jobs**: Automated scraper execution

### **Local Development**
- **Backend**: `python backend/main.py`
- **Frontend**: `npm start` in frontend directory
- **Database**: Local PostgreSQL instance

## ğŸ”® **Future Enhancements**

### **Phase 5: Advanced Features**
- **Real-time Updates**: WebSocket integration
- **Advanced Analytics**: Chart.js integration
- **User Authentication**: JWT-based auth system
- **Data Export**: CSV/Excel export functionality
- **Email Notifications**: Scraper status alerts

### **Phase 6: Enterprise Features**
- **Multi-tenant Support**: Organization-based data isolation
- **API Rate Limiting**: Advanced request throttling
- **Audit Logging**: Complete action tracking
- **Backup & Recovery**: Automated data protection
- **Monitoring Dashboard**: System health metrics

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ **License**

This project is licensed under the MIT License.

---

**Built with â¤ï¸ using FastAPI, React, SQLAlchemy, and Tailwind CSS**

**Current Status: Frontend & Backend Complete - Ready for Railway Deployment! ğŸ‰** 